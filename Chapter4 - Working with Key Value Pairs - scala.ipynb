{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Working with Key/Value Pairs\n",
    "\n",
    "## Pair RDDs\n",
    "* Spark provides special operations on RDDs containing key/value pairs - these RDDs are called pair RDDs\n",
    "* We can use the <code>map()</code> function to create a pair RDD as shown below\n",
    "* Pair RDDs are still RDDs (of Tuple2 objects in Java/Scala or of Python tuples) \n",
    "\n",
    "### Example: Creating a pair RDD using the first word as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from map: \n",
      "(his,his name is pat)\n",
      "(his,his name is peter)\n",
      "(his,his name is olaf)\n",
      "(her,her name is Joanne)\n",
      "(her,her name is Therese)\n",
      "(they,they work at algebraix in Encintas )\n",
      "(they,they like to eat yogurt )\n",
      "\n",
      "Results from lookup: \n",
      "her name is Joanne\n",
      "her name is Therese\n"
     ]
    }
   ],
   "source": [
    "val lines = sc.textFile(\"name_example.txt\")\n",
    "val rddpair = lines.map(x => (x.split(\" \")(0),x))\n",
    "\n",
    "\n",
    "println(\"Results from map: \")\n",
    "rddpair.collect().foreach(println)\n",
    "\n",
    "println(\"\\nResults from lookup: \")\n",
    "rddpair.lookup(\"her\").foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations on Pair RDDs\n",
    "\n",
    "### Transformation on one pair RDD\n",
    "* Pair RDDs are allowed to use all the transformations available to standard RDDs\n",
    "* The same rules apply from \"Passing Functions to Spark\" from Chapter 3\n",
    "    - Since pair RDDs contain tuples, we need to pass functions that operate on tuples rather than on individual elements\n",
    "* <code>reduceByKey(func)</code>: Combine values with the same key \n",
    "    - Note that calling <code>reduceByKey()</code> and <code>foldByKey()</code> will automatically perform combining locally on each machine before computing global totals for each key and hte user does not need to specify a combiner\n",
    "    - The more general <code>combineByKey</code> interface allows you to customize combining behavior\n",
    "    \n",
    "* <code>groupByKey()</code>: Group values with the same key\n",
    "* <code>combineByKey(createCombiner,mergeValue,mergeCombiners,partitioner)</code>: Combine values with the same key using a different result type\n",
    "    - <code>combineByKey()</code> is the most general of the per-key aggregation functions\n",
    "    - Most of the other per-key combiners are implemented using it\n",
    "    - Like <code>aggregate</code>, <code>combineByKey()</code> allows the user to return values that are not hte same type as our input data \n",
    "    - Understsanding <code>combineByKey()</code> in depth:<br>\n",
    "    For each element in the partition, the element either has a key it hasn't seen before or has the same key as a previous element:\n",
    "        - If it's a new element, <code>combineByKey()</code> uses a function we provide, called <code>createCombiner()</code> to create the initial value for the accumulator on the key (**Note: This happens the first time a key is found in each partition rather than only the first time the key is found in the RDD**)\n",
    "        - If it is a value we have seen before while processing that partition, it will instead use the provided function, <code>mergeValue()</code>, with the current value for the accumulator for that key and the new value\n",
    "        - <code>mergeCombiners()</code>: merges the accumulators of the same key across all partitions\n",
    "* <code>mapValues(func)</code>: Apply a function to each value of a pair RDD without changing they key\n",
    "* <code>flatMapValues(func)</code>: Apply a function taht returns an iterator to each value of a pair RDD, and for each element returned produce a key/value entry with the old key. Often used for tokenization \n",
    "* <code>keys()</code>: Return an RDD of just the keys\n",
    "* <code>values()</code>: Return an RDD of just the values\n",
    "* <code>sortByKey()</code>: Return an RDD sorted by the key\n",
    "\n",
    "### Transformation on two pair RDDs\n",
    "* <code> rdd.subtractByKey(other)</code>: Remove elements with a key present in the other RDD\n",
    "* <code> rdd.join(other)</code>: Perform an inner join between two RDDs\n",
    "* <code> rdd.rightOuterJoin(other)</code>: Perform a join between two RDDs where the key must be present in the first RDD \n",
    "* <code> rdd.leftOuterJoin(other)</code>: Perform a join between two RDDs where the key must be present in the other RDD\n",
    "* <code> rdd.cogroup(other)</code>: Group data from both RDDs sharing the same key. \n",
    "    - <code>cogroup()</code> over two RDDs sharing the same key type, K, with the respective value types V and W returns <code>RDD[(K,(Iterable[V]),Iterable[W]))]</code>\n",
    "    - If one of the RDDs doesn't have elements for a given key that is present in the other RDD, the corresponding <code>Iterable</code> is simply empty\n",
    "    - can be used to implement intersection by key\n",
    "    - can work on three or more RDDs at once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on one pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd: (3,2),(1,4),(3,6),(3,1)\n",
      "reduceByKey example: (1,4),(3,9)\n",
      "groupByKey example: (1,List(4)),(3,List(2, 6, 1))\n",
      "mapValues example: (3,3),(1,5),(3,7),(3,2)\n",
      "flatMapValues example:\n",
      "\tbefore flatMapValues:(3,Range(2, 3)),(1,Range()),(3,Range()),(3,Range(1, 2, 3))\n",
      "\tafter flatMapValues: (3,2),(3,3),(3,1),(3,2),(3,3)\n",
      "keys example: 3,1,3,3\n",
      "values example: 2,4,6,1\n",
      "sortByKey example: (1,4),(3,2),(3,6),(3,1)\n"
     ]
    }
   ],
   "source": [
    "val rdd = sc.parallelize(List((3,2),(1,4),(3,6),(3,1)))\n",
    "println(\"rdd: \" + rdd.collect().mkString(\",\"))\n",
    "\n",
    "//add values with the same key \n",
    "println(\"reduceByKey example: \" + rdd.reduceByKey(_ + _).collect().mkString(\",\"))\n",
    "\n",
    "//groupByKey() returns an iterable in the values, the mapValues function below converts the iterable to a list\n",
    "println(\"groupByKey example: \" + rdd.groupByKey().mapValues(x => x.toList).collect().mkString(\",\"))\n",
    "\n",
    "//mapValues example\n",
    "println(\"mapValues example: \" + rdd.mapValues(_ + 1).collect().mkString(\",\"))\n",
    "\n",
    "//flatMap example:\n",
    "// rdd.flatMapValues(x => (x to 3)).collect()\n",
    "println(\"flatMapValues example:\")\n",
    "println(\"\\tbefore flatMapValues:\" + rdd.mapValues(x=>(x to 3)).collect().mkString(\",\"))\n",
    "println(\"\\tafter flatMapValues: \" + rdd.flatMapValues(x=>(x to 3)).collect().mkString(\",\"))\n",
    "println(\"keys example: \" + rdd.keys.collect().mkString(\",\"))\n",
    "println(\"values example: \" + rdd.values.collect().mkString(\",\"))\n",
    "println(\"sortByKey example: \" + rdd.sortByKey().collect().mkString(\",\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:1: error: identifier expected but '(' found.\n",
       "       type((1,2))\n",
       "           ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala211",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
